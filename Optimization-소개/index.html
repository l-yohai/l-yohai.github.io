<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Optimization 소개 - YOHAI</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Yohan Lee"><meta name="msapplication-TileImage" content="/image/avatar.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Yohan Lee"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="“Language is the source of misunderstandings” - Antoine de Saint-Exupery (1900-1944) 용어에 대한 정리를 하고 넘어가야 이후에 오해가 생기지 않는다. 용어 통일이 가장 중요하기 때문에 용어에 대한 명확한 컨셉을 잡아볼 것임."><meta property="og:type" content="blog"><meta property="og:title" content="Optimization 소개"><meta property="og:url" content="https://l-yohai.github.io/Optimization-%EC%86%8C%EA%B0%9C/"><meta property="og:site_name" content="YOHAI"><meta property="og:description" content="“Language is the source of misunderstandings” - Antoine de Saint-Exupery (1900-1944) 용어에 대한 정리를 하고 넘어가야 이후에 오해가 생기지 않는다. 용어 통일이 가장 중요하기 때문에 용어에 대한 명확한 컨셉을 잡아볼 것임."><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://l-yohai.github.io/image/image-20210810115422718.png"><meta property="og:image" content="https://l-yohai.github.io/image/image-20210810115942627.png"><meta property="og:image" content="https://l-yohai.github.io/image/image-20210810121100476.png"><meta property="og:image" content="https://l-yohai.github.io/image/image-20210810121147484.png"><meta property="og:image" content="https://l-yohai.github.io/image/image-20210810124638736.png"><meta property="og:image" content="https://l-yohai.github.io/image/image-20210810124923744.png"><meta property="article:published_time" content="2021-08-10T09:19:10.000Z"><meta property="article:modified_time" content="2021-08-22T09:19:53.906Z"><meta property="article:author" content="Yohan Lee"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/image/image-20210810115422718.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://l-yohai.github.io/Optimization-%EC%86%8C%EA%B0%9C/"},"headline":"Optimization 소개","image":["https://l-yohai.github.io/image/image-20210810115422718.png","https://l-yohai.github.io/image/image-20210810115942627.png","https://l-yohai.github.io/image/image-20210810121100476.png","https://l-yohai.github.io/image/image-20210810121147484.png","https://l-yohai.github.io/image/image-20210810124638736.png","https://l-yohai.github.io/image/image-20210810124923744.png"],"datePublished":"2021-08-10T09:19:10.000Z","dateModified":"2021-08-22T09:19:53.906Z","author":{"@type":"Person","name":"Yohan Lee"},"publisher":{"@type":"Organization","name":"YOHAI","logo":{"@type":"ImageObject","url":"https://l-yohai.github.io/image/logo.png"}},"description":"“Language is the source of misunderstandings” - Antoine de Saint-Exupery (1900-1944) 용어에 대한 정리를 하고 넘어가야 이후에 오해가 생기지 않는다. 용어 통일이 가장 중요하기 때문에 용어에 대한 명확한 컨셉을 잡아볼 것임."}</script><link rel="canonical" href="https://l-yohai.github.io/Optimization-%EC%86%8C%EA%B0%9C/"><link rel="alternate" href="/rss.xml" title="YOHAI" type="application/atom+xml"><link rel="icon" href="/image/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="preconnect" href="https://fonts.gstatic.com"><link href="https://fonts.googleapis.com/css2?family=Jua:wght@400&amp;family=Source+Code+Pro" rel="stylesheet"><link rel="preconnect" href="https://fonts.gstatic.com"><link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@700&amp;family=Source+Code+Pro" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-FE2M7J88MT" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-FE2M7J88MT');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/image/logo.png" alt="YOHAI" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/l-yohai"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="카탈로그" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-10T09:19:10.000Z" title="2021. 8. 10. 오후 6:19:10">2021-08-10</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:19:53.906Z" title="2021. 8. 22. 오후 6:19:53">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">25분안에 읽기 (약 3725 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile">Optimization 소개</h1><div class="content"><p>“Language is the source of misunderstandings” - Antoine de Saint-Exupery (1900-1944)</p>
<p>용어에 대한 정리를 하고 넘어가야 이후에 오해가 생기지 않는다. 용어 통일이 가장 중요하기 때문에 용어에 대한 명확한 컨셉을 잡아볼 것임.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><ul>
<li>First-order iterative optimization algorithm for finding a local minimum of a differentiable function.</li>
<li>찾고자 하는 파라미터에 대해서 손실함수를 미분한 편미분값을 가지고 학습을 하겠다는 것임.</li>
<li>Local minimum: 손실함수를 미분했을 때 극소적으로 좋은 로컬 미니멈을 찾는 것을 목적으로 함.</li>
</ul>
<h2 id="Important-Concepts-in-Optimization"><a href="#Important-Concepts-in-Optimization" class="headerlink" title="Important Concepts in Optimization"></a>Important Concepts in Optimization</h2><ul>
<li><p>Generalization (일반화)</p>
<ul>
<li>대부분의 경우 일반화 성능을 높이는 것이 목적이다.</li>
<li>일반화 성능을 높이기만 하면 좋은 것인가?<ul>
<li>일반적으로 학습을 시키게 되면 Iteration이 지나면서 Training Error를 줄이게 되는데, Training Error가 0이 되었다고 해서 우리가 항상 원하는 최적값에 도달했다는 보장이 없다.</li>
<li>일반적으로 Training error가 주어지지만, 어느정도 시간이 지나고 나면 Test Error가 커짐, 즉 학습에 사용하지 않은 데이터에 대해서는 성능이 오히려 떨어지게 된다.</li>
<li>즉, 일반적으로 일반화는 테스트에러와 트레이닝 에러의 갭을 줄이는 것을 의미한다.</li>
<li>만약 우리 네트워크가 안좋아서 학습데이터에 대한 성능이 안좋으면, 일반화의 퍼포먼스가 좋다고 해서 테스트 데이터의 성능이 좋다고 말할 수 없다.</li>
<li>일반화의 성능은 테스트와 트레이닝 에러의 갭을 말하기 때문이다.</li>
</ul>
</li>
</ul>
</li>
<li><p>Under-fitting vs. over-fitting</p>
<ul>
<li><p>학습데이터에 대해서는 잘 동작을 하지만 테스트데이터에 대해서 잘 동작하지 않는 것을 OverFitting이라고 한다.</p>
<p><img src="/image/image-20210810115422718.png" alt></p>
</li>
</ul>
</li>
<li><p>Cross validation</p>
<ul>
<li>일반적으로 데이터가 분리되어 있음 (Train, Test, Validate)</li>
<li>보통은 학습 데이터로 학습시킨 모델이 학습에 사용되지 않은 밸리데이션 데이터를 기준으로 학습이 잘 되었는지 확인하는 과정이다.</li>
<li>하지만, 트레인과 테스트를 반반으로 했을 때, 트레인을 80 테스트를 20으로 했을 때 등 Split 범위에 따라서 학습의 퍼포먼스가 달라질 수 있다. 이러한 것을 해결하고자 하는 것이 Cross Validation이다. (혹은 K-Fold Validation)</li>
<li>네트워크를 학습할 때 수많은 파라미터가 존재한다. 또한 Hyper Parameter들에 대한 기준이 없다. 따라서 Cross-validation을 통해 최적의 Parameter Sets 을 찾고, 파라미터를 보정한 상태에서 모든 학습데이터를 학습에 사용해야 더 많은 데이터를 사용할 수 있다.</li>
<li>Test Data는 어떠한 방법으로든 학습에 사용되어서는 안된다. 즉, 학습에는 Train과 Validate 데이터만을 이용해야 한다.</li>
</ul>
</li>
<li><p>Bias-variance tradeoff</p>
<ul>
<li><p><img src="/image/image-20210810115942627.png" alt></p>
</li>
<li><p>사격을 할 때 항상 같은 곳에만 찍히면 (원점이 아니더라도) 좋은 것이다. 전체 모델을 어느정도 평준화 시키면 최적값에 도달할 가능성이 많기 때문이다. 이것을 Low Variance라고 한다. (출력이 얼마나 일관적으로 나오는 지)</p>
</li>
<li><p>이것에 반해 Variance가 크면 비슷한 입력이 들어와도 출력이 많이 달라지는 것을 의미한다.</p>
</li>
<li><p>Bias라는 것은 출력에 따른 평균적으로 True Target에 접근하는 정도를 의미하며, Bias가 크면 Mean에서 많이 벗어나는 것을 의미한다.</p>
</li>
<li><p>학습 데이터에 Noise가 껴있다고 가정했을 때 내가 이 노이즈가 껴있는 타겟 데이터를 미니마이즈하는 것에 대하여 세 파트로 나뉘어진다. 내가 미니마이즈하는 것은 하나의 값(cost)이지만, 그 값은 세 파트로 나뉘어져 있어서 한 파트를 줄이면 다른 파트가 커질 수밖에 없는 Trade-off 관계이다.</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}\left[(t-\hat{f})^{2}\right] &=\mathbb{E}\left[(t-f+f-\hat{f})^{2}\right] \\
&=\ldots \\
&=\mathbb{E}\left[\left(f-\mathbb{E}[\hat{f}]^{2}\right)^{2}\right]+\mathbb{E}\left[(\mathbb{E}[\hat{f}]-\hat{f})^{2}\right]+\mathbb{E}[\epsilon]
\end{aligned}</script><p>위 식에서 cost를 minimize한다는 것은 bias와 variance, noise를 minimize 한다는 것을 의미한다.</p>
</li>
</ul>
</li>
<li><p>Bootstrapping</p>
<ul>
<li>신발끈을 말하는 것이며, 그 뜻은 신발끈을 들어올려 하늘을 날겠다라는 허황된 뜻임.</li>
<li>딥러닝에서는 학습 데이터가 100개가 있다고 하면, 100개 중 80개를 사용하겠다 등 일부만 뽑아서 사용한다는 것을 의미한다.</li>
<li>이렇게 했을 때 하나의 입력에 대해서 각 모델들의 출력이 달라질 수 있다. 이 때 각 모델들의 예측값들이 얼마나 일치를 이루는지 보고 전체 모델들의 특성을 알고자 하는 것이다.</li>
<li>학습데이터가 고정되어 있을 때 subsampling을 통해 여러 학습데이터를 만들고 그것을 이용하여 여러 모델 혹은 metric을 만들겠다는 것임.</li>
</ul>
</li>
<li><p>Baggin and boosting</p>
<ul>
<li>Bagging(Bootstrapping aggregating)</li>
<li>학습데이터를 여러 개를 만들어서 (Booststrapping) 여러 모델을 만들고 그 모델의 output들을 가지고 평균을 내겠다는 뜻임.</li>
<li>학습데이터가 고정되어 있으면 이것을 모두 이용하여 하나의 결과를 내는 것이 좋을 것 같지만 사실은 그렇지 않다. N개의 모델을 만들고, N개의 모델의 출력값의 평균이나 Voting을 통해 나오는 결과를 사용하는 것이 보통 성능이 더 좋다.</li>
<li>Boosting: 학습데이터를 시퀀셜하게 바라봐서 간단한 모델을 만들고, 모델에 학습데이터를 다 넣어본다. 모델에서 80개는 잘 예측을 했지만 20개는 잘 안되었다. 이 때 모델을 하나를 더 만드는데 전에 안되었던 20개에 데이터를 잘 예측하는 모델을 만든다. 이렇게 모델들을 만들고 합친 이후에 하나의 struct learner를 만들고, 그 weight를 찾는 방식을 말한다.</li>
</ul>
</li>
</ul>
<h2 id="Practical-Gradient-Descent-Methods"><a href="#Practical-Gradient-Descent-Methods" class="headerlink" title="Practical Gradient Descent Methods"></a>Practical Gradient Descent Methods</h2><h3 id="Stochastic-gradient-Descent"><a href="#Stochastic-gradient-Descent" class="headerlink" title="Stochastic gradient Descent"></a>Stochastic gradient Descent</h3><ul>
<li>하나의 샘플을 이용</li>
</ul>
<h3 id="Mini-batch-Gradient-Descent"><a href="#Mini-batch-Gradient-Descent" class="headerlink" title="Mini-batch Gradient Descent"></a>Mini-batch Gradient Descent</h3><ul>
<li>Subset of data 를 사용</li>
</ul>
<h3 id="Batch-Gradient-Descent"><a href="#Batch-Gradient-Descent" class="headerlink" title="Batch Gradient Descent"></a>Batch Gradient Descent</h3><ul>
<li>whole data 를 사용</li>
</ul>
<h2 id="Batch-size-Matters"><a href="#Batch-size-Matters" class="headerlink" title="Batch-size Matters"></a>Batch-size Matters</h2><ul>
<li><p>배치사이즈는 굉장히 중요하다.</p>
<p><img src="/image/image-20210810121100476.png" alt></p>
</li>
<li><p>엄청나게 큰 배치를 사용하게 되면 Sharp Minimizers에 도달한다. 하지만 작은 배치를 사용하면 Flat Minimizers에 도달한다.</p>
</li>
<li><p>배치사이즈를 작게 사용하는 것이 일반적으로 좋다. sharp보단 flat이 더 좋다는 것임.</p>
<p><img src="/image/image-20210810121147484.png" alt></p>
</li>
<li><p>우리의 목적은 Train function에서 잘 동작하는 것이 아니라 Testing function에 잘 동작하는 것이다. 이 때 Flat Minimum은 Testing 값이 잘 나오지만, Sharp Minimum의 경우 한 번도 트레인에 사용되지 않은 데이터에서는 잘 동작하지 않는다.</p>
</li>
</ul>
<h2 id="Gradient-Descent-Methods"><a href="#Gradient-Descent-Methods" class="headerlink" title="Gradient Descent Methods"></a>Gradient Descent Methods</h2><p>구현할 필요는 전혀 없음! 딥러닝 프레임워크에서는 한 줄 컷이다.</p>
<ul>
<li><p>Stochastic Gradient Descent</p>
<ul>
<li>가장 큰 단점은 Lr, stepsize를 잡는 것이 가장 어렵다는 것이다. 너무 크면 학습이 안되고, 너무 작으면 학습을 오래 시켜도 학습이 안된다.</li>
<li>$W_{t + 1} \leftarrow W_t - \eta g_t$</li>
<li>$\eta$ : Learning rate or step size</li>
<li>$g_t$: Gradient</li>
</ul>
</li>
<li><p>Momentum (관성)</p>
<ul>
<li><p>SGD의 단점을 극복하기 위해 제시된 Optimization 테크닉이다.</p>
</li>
<li><p>한 번 Gradient가 한 방향으로 흐른 이후 다음 Gradient 가 조금 다른 방향으로 흘렀어도, 이전 방향으로 흘렀던 정보를 활용해보자.</p>
</li>
<li><script type="math/tex; mode=display">
a_{t+1} \leftarrow \beta a_t + g_t \\
W_{t+1} \leftarrow W_t - \eta a_{t+1}</script></li>
</ul>
</li>
</ul>
<ul>
<li><p>$a_{t+1}$ : Accumulation</p>
</li>
<li><p>$\beta$ : Momentum</p>
</li>
<li><p>모멘텀과 현재 기울기를 합친 Accumulation으로 Update를 한다.</p>
</li>
<li><p>장점은 한 번 흘러간 기울기를 포함하여 업데이트를 하기 때문에 어느정도 학습이 잘 이루어지게 된다.</p>
</li>
</ul>
<ul>
<li><p>Nesterov Accelerated Gradient</p>
<ul>
<li><p>이것도 역시 a라고 하는 Accumulate 가 업데이트를 하는 것인데, 기울기를 계산할 때 Lookahead gradient를 계산하게 된다.</p>
</li>
<li><p>모멘텀은 이전 기울기 정보로 계산하는데, 이 친구는 a라고 하는 현재 정보가 있다면 그 방향으로 한 번 가보고 기울기를 계산한 다음에 그 기울기를 가지고 Accumulation을 계산한다.</p>
</li>
<li><script type="math/tex; mode=display">
\begin{aligned}
a_{t+1} & \leftarrow \beta a_{t}+ \nabla \mathcal{L} (W_{t}-\eta \beta a_{t})\\
W_{t+1} & \leftarrow W_{t}-\eta a_{t+1}
\end{aligned}</script></li>
<li><p>일반적으로 모멘텀을 관성으로 해석한다면, Local Minimum으로 Conversion 하지 못하는 현상이 생길 수 있는데 이에 반해 NAG는 Local Minimum을 지나서 기울기를 계산하는 것이 아니라 한 번 지나간 그 점에서 기울기를 계산하는 것이기 때문에 Local Minimum이 한 쪽 아래로 흘러갈 수 있다는 장점이 있다. 즉, 극값에 조금 더 빠르게 접근할 수 있다는 장점이 있다.</p>
</li>
</ul>
</li>
<li><p>Adagrad</p>
<ul>
<li>신경망의 파라미터가 변했는지 안변했는지를 보게 되고 많이 변한 파라미터들은 적게 변화시키고 조금 변한 파라미터는 많이 변화시키기 위해 고안된 Adaptive Learning 이다.</li>
<li>즉 파라미터들이 얼마나 변했는지를 기록한 정보가 필요하다.</li>
<li>$W_{t+1}=W_{t}-\frac{\eta}{\sqrt{G_{t}}+\epsilon} g_{t}$​​​</li>
<li>$G_t$: sum of gradient squares</li>
<li>가장 큰 문제는 $G_t$ 라는 것이 계속해서 커지기 때문에 결국에는 무한대로 가게 되면 분모가 무한대니까 W의 업데이트가 안되게 된다. 즉 뒤로 갈 수록 학습이 점점 되지 않는 문제가 생긴다. 이것을 해결하기 위해 고안된 방법이 Adam 등이다.</li>
</ul>
</li>
<li><p>Adadeltha</p>
<ul>
<li><script type="math/tex; mode=display">
\begin{aligned}
G_{t} &=\gamma G_{t-1}+(1-\gamma) g_{t}^{2} \\
W_{t+1} &=W_{t}-\frac{\sqrt{H_{t-1}+\epsilon}}{\sqrt{G_{t}+\epsilon}} g_{t} \\
H_{t} &=\gamma H_{t-1}+(1-\gamma)\left(\Delta W_{t}\right)^{2}
\end{aligned}</script></li>
<li><p>Adagrad가 가지는 $G_t$가 커지는 것을 막기 위해 고안된 방법 중 하나이다.</p>
</li>
<li><p>타임스텝 t가 주어졌을 때 $G_t$ 를 윈도우 사이즈 만큼의 파라미터, 시간에 따른 기울기 변화를 보겠다는 것임.</p>
</li>
<li><p>이것 역시 문제가 있음. 윈도우 사이즈를 100으로 잡았을 때 100회 정보에 대한 값을 가지고 있어야 한다. 즉 GPU가 터질 수도 있다. 이것을 $H_t$ 를통해 해결할 수 있다.</p>
</li>
<li><p>Adadelta의 가장 큰 특징은 Learning rate가 없다는 것인데, 그 뜻은 우리가 무언가를 시도해볼 것이 적다는 뜻이다. 따라서 잘 쓰이지 않는다.</p>
</li>
</ul>
</li>
<li><p>RMSprop</p>
<ul>
<li><p>논문을 통해서 제안된 방법이 아니다.</p>
</li>
<li><p>아이디어는 간단함.</p>
</li>
<li><script type="math/tex; mode=display">
\begin{aligned}
G_{t} &=\gamma G_{t-1}+(1-\gamma) g_{t}^{2} \\
W_{t+1} &=W_{t}-\frac{\eta}{\sqrt{G_{t}+\epsilon}} g_{t}
\end{aligned}</script></li>
<li><p>Adagrad 처럼 Gradient Squares를 그냥 더하는 것이 아니라 분모에 넣고, $\eta$ 라는 stepsize가 들어간다.</p>
</li>
</ul>
</li>
<li><p>Adam</p>
<ul>
<li><p>일반적으로 가장 무난하게 사용하는 것이 바로 Adam이다.</p>
</li>
<li><script type="math/tex; mode=display">
\begin{aligned}
m_{t} &=\beta_{1} m_{t=1}+\left(1-\beta_{1}\right) g_{t} \\
v_{t} &=\beta_{2} v_{t-1}+\left(1-\beta_{2}\right) g_{t}^{2} \\
W_{t+1} &=W_{t}-\frac{\eta}{\sqrt{v_{t}+\epsilon}} \frac{\sqrt{1-\beta_{2}^{t}}}{1-\beta_{1}^{t}} m_{t}
\end{aligned}</script></li>
<li><p>$m_t$ : momentum</p>
</li>
<li><p>$v_t$ : EMA of gradient squares</p>
</li>
<li><p>Gradient 크기에 따라서 Adaptive하게 Learning rate를 바꾸는 것과 이전 Gradient 정보에 해당하는 모멘텀을 잘 합친 방법이다.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p>학습에 잘 되는 것을 방해하기 위해 규제하는 것임. 학습을 방해함으로써 얻기 위한 목적을 잘 생각해야 한다. 즉, 학습데이터가 잘 되기 위해 사용하는 것이 아니라 방해함으로써 테스트데이터에도 잘 동작하도록 만드는 것이다.</p>
<ul>
<li><p>Early stopping</p>
<ul>
<li>학습을 일찍 멈추는 것. 하지만 학습을 멈출 때 테스트 데이터를 사용하면 Cheating이기 때문에 Validation Data를 사용한다.</li>
<li>Loss 가 어느 순간부터 커질 수 있는 데 그 시점에 빠르게 학습을 멈추자는 것임.</li>
</ul>
</li>
<li><p>Parameter norm penalty</p>
<ul>
<li>신경망 파라미터가 너무 커지지 않게 하는 것임. 각 파라미터들을 제곱한 다음에 더하면 어떤 숫자가 나올텐데, 그 숫자를 같이 줄이는 것이다.</li>
<li>이왕이면 네트워크 웨이트의 숫자가 작을 수록 좋다. ‘크기’에 관점에서.</li>
<li>물리적이거나 해석적인 관점에서의 의미는 뉴럴넷이 만드는 함수의 공간속에서 함수를 최대한 부드러운 함수로 보자는 것이다. 부드러운 함수일수록 일반화 성능이 높다는 것일 것이다라는 가정이 전제됨.</li>
</ul>
</li>
<li><p>Data augmentation</p>
<ul>
<li><p>딥러닝에서 가장 중요한 것 중 하나가 데이터이다.</p>
</li>
<li><p>데이터가 적으면 딥러닝보다 전통적인 ML(XG Boost, Random Forest 등)이 훨씬 성능이 높다.</p>
</li>
<li><p>하지만 데이터가 커질수록 머신러닝 방법론들보다 딥러닝 방법론이 훨씬 성능이 좋다.</p>
</li>
<li><p>하지만 데이터는 한정적이기 때문에 Augmentation을 통해 어떠한 방법으로든 데이터를 늘리는 것이다.</p>
<p><img src="/image/image-20210810124638736.png" alt></p>
</li>
</ul>
</li>
<li><p>Noise robustness</p>
<ul>
<li>왜 잘되는지는 아직 의문이 있다.</li>
<li>Data Augmentation이랑 비슷할 수도 있지만, 데이터에 노이즈를 집어넣는 방식이다. 굳이 차이를 두자면 입력에만 노이즈를 두는 것이 아니라 weight에도 noise를 주는 것이다.</li>
</ul>
</li>
<li><p>Label smoothing</p>
<ul>
<li>데이터 두 개를 뽑아서 Train 단계의 데이터 두 개를 섞어주는 것이다.</li>
<li>일반적으로 분류 문제에서 Descision Boundary를 찾는 것이 목적인데, Descision Boundary 를 조금 더 부드럽게 만들어주는 효과가 있다.</li>
<li><img src="/image/image-20210810124923744.png" alt></li>
<li>라벨을 섞고 이미지(학습데이터)도 섞는 방법임.</li>
<li>왜 잘되는지가 설명되기 보다는 그냥 하면 잘 된다.</li>
</ul>
</li>
<li><p>Dropout</p>
<ul>
<li>신경망의 weight를 0으로 바꾸는 것이다.</li>
<li>각각의 뉴런들이 더욱 Robust한 Feature를 얻을 수 있다고 해석을 한다.</li>
</ul>
</li>
<li><p>Batch normalization</p>
<ul>
<li>논란이 많은 논문이다.</li>
<li>적용하려는 레이어에 Statistics를 정규화 시키는 것이다.</li>
<li>천개의 파라미터가 있는 히든레이어라면, 천개의 파라미터의 각각의 값들에 대한 statistics에 대해 평균을 빼주고 표준편차를 나눠주는 방식이다.</li>
<li>활용하면 성능이 많이 올라간다.</li>
</ul>
</li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Optimization 소개</p><p><a href="https://l-yohai.github.io/Optimization-소개/">https://l-yohai.github.io/Optimization-소개/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Yohan Lee</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-08-10</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-08-22</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="external nofollow noopener noreferrer" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="external nofollow noopener noreferrer" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="external nofollow noopener noreferrer" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/%EB%B9%9B%EC%98%88%EB%8B%AE%ED%8A%B9%EA%B0%95-%EB%85%BC%EB%AC%B8%EC%9D%BD%EB%8A%94%EB%B2%95/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">빛예닮특강 - 논문읽는법</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/CV-NLP-%EC%84%A0%ED%83%9D%EA%B0%80%EC%9D%B4%EB%93%9C-%EC%97%85%EC%8A%A4%ED%85%8C%EC%9D%B4%EC%A7%80-%EC%84%9C%EB%8C%80%EC%9B%90-%EB%B0%95%EC%84%A0%EA%B7%9C/"><span class="level-item">CV &amp; NLP 선택가이드 - 업스테이지 서대원, 박선규</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">댓글</h3><script src="https://utteranc.es/client.js" repo="l-yohai/l-yohai.github.io" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/image/avatar.jpg" alt="YOHAI"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">YOHAI</p><p class="is-size-6 is-block">Your Own Humanistic AI</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">65</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">21</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">26</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/l-yohai" target="_blank" rel="external nofollow noopener noreferrer">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="external nofollow noopener noreferrer" title="Github" href="https://github.com/l-yohai"><i class="fab fa-github"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/42-Life/"><span class="level-start"><span class="level-item">42 Life</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Boostcamp-AI-Tech/"><span class="level-start"><span class="level-item">Boostcamp AI Tech</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Boostcamp-AI-Tech/Master-Class/"><span class="level-start"><span class="level-item">Master Class</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Diary/"><span class="level-start"><span class="level-item">Diary</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Paper-Review/"><span class="level-start"><span class="level-item">Paper Review</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Problem-Solving/"><span class="level-start"><span class="level-item">Problem Solving</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/Project/"><span class="level-start"><span class="level-item">Project</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Study/"><span class="level-start"><span class="level-item">Study</span></span><span class="level-end"><span class="level-item tag">30</span></span></a><ul><li><a class="level is-mobile" href="/categories/Study/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/C/"><span class="level-start"><span class="level-item">C</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Math-for-AI/"><span class="level-start"><span class="level-item">Math for AI</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Study/NLP/MRC/"><span class="level-start"><span class="level-item">MRC</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Study/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Visualization/"><span class="level-start"><span class="level-item">Visualization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Yonsei/"><span class="level-start"><span class="level-item">Yonsei</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/fur-Musik/"><span class="level-start"><span class="level-item">für Musik</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/42-Seoul/"><span class="tag">42 Seoul</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42Seoul/"><span class="tag">42Seoul</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42%EC%84%9C%EC%9A%B8/"><span class="tag">42서울</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42%EC%84%9C%EC%9A%B8-%EB%B3%B8%EA%B3%BC%EC%A0%95/"><span class="tag">42서울 본과정</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42%EC%84%9C%EC%9A%B8-%ED%9B%84%EA%B8%B0/"><span class="tag">42서울 후기</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI-%EB%8C%80%ED%9A%8C-%ED%98%91%EC%97%85-%ED%94%8C%EB%9E%98%EB%8B%9D%EA%B0%80%EC%9D%B4%EB%93%9C/"><span class="tag">AI, 대회, 협업, 플래닝가이드</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Franz-Liszt/"><span class="tag">Franz Liszt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kakao-I-Open-Builder/"><span class="tag">Kakao I Open Builder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/La-Piscine/"><span class="tag">La Piscine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Papago-NMT-API/"><span class="tag">Papago NMT API</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Teachable-Machine/"><span class="tag">Teachable Machine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Seminar/"><span class="tag">Tech Seminar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VoyagerX/"><span class="tag">VoyagerX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WaveNet/"><span class="tag">WaveNet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word2Vec/"><span class="tag">Word2Vec</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B3%B5%ED%86%B5%EA%B3%BC%EC%A0%95/"><span class="tag">공통과정</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%82%A8%EC%84%B8%EB%8F%99/"><span class="tag">남세동</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="tag">딥러닝</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B3%B4%EC%9D%B4%EC%A0%80%EC%97%91%EC%8A%A4/"><span class="tag">보이저엑스</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"><span class="tag">시각화</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%B4%EC%A0%95/"><span class="tag">열정</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9D%B4%EB%84%88%EC%84%9C%ED%81%B4/"><span class="tag">이너서클</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98%EC%95%84%EC%B9%B4%EB%8D%B0%EB%AF%B8/"><span class="tag">이노베이션아카데미</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%B1%97%EB%B4%87/"><span class="tag">챗봇</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%B4%88%EC%A0%88%EA%B8%B0%EA%B5%90-%EC%97%B0%EC%8A%B5%EA%B3%A1/"><span class="tag">초절기교 연습곡</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%86%A1/"><span class="tag">카카오톡</span><span class="tag">2</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">카탈로그</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Gradient-Descent"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Gradient Descent</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Important-Concepts-in-Optimization"><span class="level-left"><span class="level-item">2</span><span class="level-item">Important Concepts in Optimization</span></span></a></li><li><a class="level is-mobile" href="#Practical-Gradient-Descent-Methods"><span class="level-left"><span class="level-item">3</span><span class="level-item">Practical Gradient Descent Methods</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Stochastic-gradient-Descent"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Stochastic gradient Descent</span></span></a></li><li><a class="level is-mobile" href="#Mini-batch-Gradient-Descent"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Mini-batch Gradient Descent</span></span></a></li><li><a class="level is-mobile" href="#Batch-Gradient-Descent"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">Batch Gradient Descent</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Batch-size-Matters"><span class="level-left"><span class="level-item">4</span><span class="level-item">Batch-size Matters</span></span></a></li><li><a class="level is-mobile" href="#Gradient-Descent-Methods"><span class="level-left"><span class="level-item">5</span><span class="level-item">Gradient Descent Methods</span></span></a></li><li><a class="level is-mobile" href="#Regularization"><span class="level-left"><span class="level-item">6</span><span class="level-item">Regularization</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-15T23:24:55.000Z">2021-10-16</time></p><p class="title"><a href="/PStage-MRC-7%EA%B0%95-Linking-MRC-and-Retrieval/">PStage MRC 7강 - Linking MRC and Retrieval</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-14T21:24:41.000Z">2021-10-15</time></p><p class="title"><a href="/PStage-MRC-6%EA%B0%95-Scaling-up-with-FAISS/">PStage MRC 6강 - Scaling up with FAISS</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-13T19:59:34.000Z">2021-10-14</time></p><p class="title"><a href="/PStage-MRC-4-5%EA%B0%95-Passage-Retrieval-Sparse-Embedding-Dense-Embedding/">PStage MRC 4-5강 - Passage Retrieval - Sparse Embedding, Dense Embedding</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-13T02:50:23.000Z">2021-10-13</time></p><p class="title"><a href="/PStage-MRC-3%EA%B0%95-Generation-based-MRC/">PStage MRC 3강 - Generation-based MRC</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-12T02:41:29.000Z">2021-10-12</time></p><p class="title"><a href="/PStage-MRC-2%EA%B0%95-Extraction-based-MRC/">PStage MRC 2강 - Extraction-based MRC</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">10월 2021</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">9월 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">8월 2021</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">4월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">12월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">9월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/08/"><span class="level-start"><span class="level-item">8월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">6월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">5월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/04/"><span class="level-start"><span class="level-item">4월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">3월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">2월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/image/logo.png" alt="YOHAI" height="28"></a><p class="is-size-7"><span>&copy; 2021 Yohan Lee</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/l-yohai"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>