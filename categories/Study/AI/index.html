<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>카테고리: AI - YOHAI</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Yohan Lee"><meta name="msapplication-TileImage" content="/image/avatar.jpg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Yohan Lee"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="YOHAI"><meta property="og:url" content="https://l-yohai.github.io/"><meta property="og:site_name" content="YOHAI"><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://l-yohai.github.io/image/og_image.jpeg"><meta property="article:author" content="Yohan Lee"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/image/og_image.jpeg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://l-yohai.github.io"},"headline":"YOHAI","image":[],"author":{"@type":"Person","name":"Yohan Lee"},"publisher":{"@type":"Organization","name":"YOHAI","logo":{"@type":"ImageObject","url":"https://l-yohai.github.io/image/logo.png"}},"description":""}</script><link rel="alternate" href="/rss.xml" title="YOHAI" type="application/atom+xml"><link rel="icon" href="/image/avatar.jpg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="preconnect" href="https://fonts.gstatic.com"><link href="https://fonts.googleapis.com/css2?family=Jua:wght@400&amp;family=Source+Code+Pro" rel="stylesheet"><link rel="preconnect" href="https://fonts.gstatic.com"><link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@700&amp;family=Source+Code+Pro" rel="stylesheet"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-FE2M7J88MT" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-FE2M7J88MT');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/image/logo.png" alt="YOHAI" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/l-yohai"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">카테고리</a></li><li><a href="/categories/Study/">Study</a></li><li class="is-active"><a href="#" aria-current="page">AI</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-13T09:26:33.000Z" title="2021. 8. 13. 오후 6:26:33">2021-08-13</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:26:43.000Z" title="2021. 8. 22. 오후 6:26:43">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">3분안에 읽기 (약 456 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Generative-Models/">Generative Models 소개</a></h1><div class="content"><p>What I cannot create, I do not understand. - Richard Feynman</p>
<p>생성 모델을 학습한다는 것에 대해서 가장 처음에 생각하는 것은 그럴듯한 문장 혹은 이미지를 만드는 것이라고 생각한다. 하지만 이것이 전부가 아니라, 생성모델은 그것보다 많은 것을 포함하는 개념이다.</p>
<p>Generation: 강아지와 같은 이미지를 만드는 것도 생성모델이 하는 일이지만, Density estimation 어떤 이미지가 들어왔을 때 확률값 하나가 튀어나와서 이미지가 고양이 같은지 강아지 같은지 강아지가 아닌 것 같은지 구분하고 싶은 것임. 이상행동감지로 활용될 수 있다. 엄밀히 생성모델은 Discrimity 모델을 포함하고 있다. 즉 생성해내는 것만 아니라 구분하는 것까지 포함하고 있다.</p>
<p>이러한 모델을 보통 explicit model 이라고 한다. 확률값을 얻을 수 있는 모델을 뜻함.</p>
<p>Unsupervised representation learning 이라고 강아지가 있으면 강아지는 귀가 두개고 꼬리가 있고 등의 특성이 있을텐데 이것을 feature learning 이라고 한다. 이 feature learning이 생성모델이 할 수 있는 것으로 표현하기도 함.</p>
<h4 id="Basic-Discrete-Distributions"><a href="#Basic-Discrete-Distributions" class="headerlink" title="Basic Discrete Distributions"></a>Basic Discrete Distributions</h4><ul>
<li>Bernoulli distribution<ul>
<li>이것을 포함하는 확률분포에는 숫자가 하나 필요함. 동전을 던졌을 때 앞 뒤가 나오는 것. 카테고리면 n개가 필요한 것. 주사위를 던졌을 때 n개가 필요한 것이 아니라 n - 1개가 필요함.</li>
</ul>
</li>
<li>Categorical distribution</li>
</ul>
<p>RGB 이미지 하나를 픽셀로 표현할 때 (r, g, b) ~ p(R, G, B) 는 256 <em> 256 </em> 256 가지가 있다. 그렇다면 이것을 표현하는 파라미터는 256 <em> 256 </em> (256 - 1) 개가 필요함.</p>
</div><a class="article-more button is-small is-size-7" href="/Generative-Models/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-13T09:25:15.000Z" title="2021. 8. 13. 오후 6:25:15">2021-08-13</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:25:51.000Z" title="2021. 8. 22. 오후 6:25:51">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">20분안에 읽기 (약 2947 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Transformer-intro/">Transformer 소개</a></h1><div class="content"><p>What makes sequential modeling a hard problem to handle?</p>
<p>문장은 항상 길이가 달라질 수도 있고 문장 어순을 바꾸는 등 문법에 항상 완벽하게 대응하는 문장을 만들지 않듯이 중간에 뭐 하나가 빠져있을 수 있음. 또한 permuted sequence라고 뭐 하나가 밀리거나 하는 등의 문제가 있을 수 있어서, 중간에 무언가가 바뀐 시퀀셜 데이터가 들어간다면 모델링이 굉장히 어려워진다. 이것을 해결하기 위해 Transformer가 등장하였고, self-attention 이라는 구조를 사용하게 된다.</p>
<p>Attention is all you need - Transformer is the first sequence transduction model based entirely on attention.</p>
<p>RNN이라는 구조에서 (하나의 입력이 들어가고, 다른 입력이 들어갈 때 이전 뉴런에서 가지고 있던 cell state가 다음 뉴런으로 들어가는 재귀적 구조) Transformer에는 재귀적인 구조가 없고, attention 구조를 활용했다는 것이 가장 큰 변화이다.</p>
<p>From a bird’s-eye view, this is what the Transformer does for machine translation tasks.</p>
<p>트랜스포머 방법론은 시퀀셜한 데이터를 처리하고 인코딩하는 문제이기 때문에 NMT에만 적용되지 않고, 이미지 분류, detection, 이미지분류, Dall-e(문장에 맞는 이미지 생성) 등 여러 태스크에서 활용되고 있다.</p>
<p>어떠한 문장이 주어졌을 때 (불어문장) 그것을 다른 문장으로 바꾸는 것을 하려고 하는 것임. 시퀀셜 데이터를 넣었을 때 시퀀셜 데이터가 나오게 하는 것.</p>
<p><img src="/image/image-20210813113655977.png" alt></p>
<p>입력 시퀀스와 출력시퀀스의 단어 숫자가 다를 수 있고, 입력 시퀀스와 출력 시퀀스의 도메인이 다를 수 있는 하나의 모델구조임.</p>
<p>원래 RNN에서는 세 개의 단어가 들어가면 세 번의 작동을 했는데, 트랜스포머에서는 세 개든 백 개든 한 번에 인코딩을 할 수 있게 된다. 이렇듯 self-attention 구조에서는 n개의 단어를 한 번에 처리할 수 있다.</p></div><a class="article-more button is-small is-size-7" href="/Transformer-intro/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-12T09:23:55.000Z" title="2021. 8. 12. 오후 6:23:55">2021-08-12</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:24:41.000Z" title="2021. 8. 22. 오후 6:24:41">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">7분안에 읽기 (약 1012 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/RNN-intro/">RNN 소개</a></h1><div class="content"><h2 id="Sequential-Model"><a href="#Sequential-Model" class="headerlink" title="Sequential Model"></a>Sequential Model</h2><ul>
<li>일상에서 다루는 대부분의 데이터가 시퀀셜 데이터다. (말, 영상 등)</li>
<li>시퀀셜 데이터를 다루는 가장 큰 어려움은, 우리가 가장 얻고 싶은 것은 어떤 영역에 어떤 정보가 있다와 같은 것인데, 시퀀셜 데이터는 길이가 얼마나 될지 모르는 것이다. 즉 데이터가 몇개의 차원으로 되어있을지 모른다는 것인데, 이것은 시퀀셜 모델은 몇 개의 데이터가 들어오든 동작할 수 있어야 한다.</li>
<li>이전에 어떤 데이터가 들어왔을 때 다음에 어떤 데이터가 들어올 지 예측하는 것이 가장 기본적인 모형이다.</li>
<li><img src="/image/image-20210812104500526.png" alt></li>
<li>과거에 고려해야 하는 정보량이 계속 늘어난다는 것이 가장 큰 어려움이다.</li>
</ul>
<p>시퀀셜 모델을 가장 간단히 만들 수 있는 방법은, Fix the past timespan 과거의 데이터를 몇 개만 보겠다고 정해두는 것이다.</p>
<ul>
<li>Autoregressive model</li>
<li>Markov model (first-order autoregressive model) 가장 큰 특징은 가정을 할 때 바로 이전 과거에만 dependent 한다는 것이다. 이러한 마르코프 모델은 과거의 많은 정보를 버릴 수밖에 없다는 단점이 있다.</li>
</ul>
<p>Latent autoregressive model</p>
<ul>
<li>위의 모델들은 과거의 많은 정보를 사용할 수 없기에 대안으로 나온 것이 Latent autoregressive model이다.</li>
<li>중간에 Hidden state가 들어가 있는데, 이것은 과거의 정보를 요약하고 있다고 생각하면 됨.</li>
<li>즉 바로 직전 과거에 의존하는 것이 아닌 hidden state에 의존하는 구조이다.</li>
</ul>
<h2 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h2><p>자기 자신으로 돌아오는 구조가 하나 있다. 나의 h_t 에서의 t에서의 hidden state는 x_t에 의존하는 것이 아니라 t - 1에서 얻어진 cell state에 의존하는 구조임.</p>
<p><img src="/image/image-20210812105017392.png" alt></p>
<p>Recurrent 구조를 시간순으로 풀게 되면 입력이 많은 FC Layer로 표현할 수 있다.</p></div><a class="article-more button is-small is-size-7" href="/RNN-intro/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-12T09:21:46.000Z" title="2021. 8. 12. 오후 6:21:46">2021-08-12</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:23:28.000Z" title="2021. 8. 22. 오후 6:23:28">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">6분안에 읽기 (약 905 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Computer-Vision-Applications-Semantic-Segmentation-and-Detection/">Computer Vision Applications (Semantic Segmentation and Detection</a></h1><div class="content"><h2 id="Semantic-Segmentation"><a href="#Semantic-Segmentation" class="headerlink" title="Semantic Segmentation"></a>Semantic Segmentation</h2><p><img src="/image/image-20210812074753902.png" alt></p>
<p>이미지 픽셀 별 분류 과제이다. Dense Classification, Perl Pixel 등으로 불리기도 한다.</p>
<ul>
<li><p>Fully Convolutional Network</p>
<ul>
<li><p>output이 1000개의 채널이라고 하면, Dense Layer를 없애고 Fully Convolutional Network 로 변경하려는 것임.</p>
</li>
<li><p>Fully Connected (Dense) Layer를 사용하는 것과 결과적으로 똑같음. 파라미터도 완전히 똑같음.</p>
<p><img src="/image/image-20210812075323907.png" alt></p>
</li>
<li><p>이러한 과정을 convolutionalization 이라고 한다.</p>
<ul>
<li>Transforming fully connected layers into convolution layers enables a classification net to output a heat map.</li>
</ul>
</li>
<li><p>While FCN can run with inputs of any size, the output dimensions(special dimension) are typically reduced by subsampling. So we need a way to connect the coarse output to the dense pixels.</p>
</li>
</ul>
</li>
<li><p>Deconvolution (conv transpose)</p>
<ul>
<li><p>직관적으로 보았을 때 Convolution의 역 연산이다.</p>
<p><img src="/image/image-20210812102230098.png" alt></p>
</li>
<li><p>special dimension을 키워주는 역할을 하게 된다.</p>
</li>
<li><p>엄밀히 말하면 convolution의 역 연산은 존재할 수 없다. 원래의 값으로 완전히 복원할 수는 없기 때문이다. 하지만 이렇게 생각하면 좋은 이유는 네트워크 구조를 짤 때 파라미터 크기와 네트워크 입출력을 계산할 때 역으로 생각하면 편하기 때문이다.</p>
</li>
</ul>
</li>
</ul>
<h2 id="Detection"><a href="#Detection" class="headerlink" title="Detection"></a>Detection</h2><p>Semantic Segmentation 이랑 비슷하지만, 퓨어픽셀을 이용한 히트맵을 찾는 것이 아니라 객체들의 bounding box를 찾는 과제로 만든 것이다.</p>
<ul>
<li>R-CNN<ol>
<li>R-CNN takes an input image,</li>
<li>extracts around 2,000 region proposals (using Selective search),</li>
<li>compute features for each proposal (using AlexNet),</li>
<li>and then classifies with lenear SVMs.</li>
</ol>
</li>
<li>SPPNet<ul>
<li>RCNN의 가장 큰 문제는 이미지에서 2000개의 바운딩박스를 뽑았을 때, 2000개의 이미지 혹은 패치를 모두 CNN에 통과시켜야 한다. 즉 하나의 이미지를 처리하는데 CPU에서는 1분의 시간이 소요되었었다.</li>
<li>이미지 전체에 대한 컨볼루션 피쳐맵을 만들고, 뽑힌 바운딩박스 위치에 해당하는 컨볼루션 피쳐맵의 텐서만 뽑아온 것으로 CNN에 통과시킴으로써 훨씬 빨라지며, 한 번의 CNN으로 결과를 얻을 수 있다.</li>
</ul>
</li>
<li>Fast R-CNN<ul>
<li><img src="/image/image-20210812103103755.png" alt></li>
<li>기본 컨셉은 SPPNet과 굉장히 유사하지만, 뒷단의 Neural Net(RoI)을 통해서 바운딩박스 리그레션과 분류를 진행했다.</li>
</ul>
</li>
<li>Faster R-CNN<ul>
<li>이미지를 통해 바운딩박스를 뽑아내는 Region Proposal 역시 학습을 시키자는 것임.</li>
<li><img src="/image/image-20210812103228562.png" alt></li>
<li>Region Proposal Network<ul>
<li>이미지가 있으면 이미지 속 특정 영역(패치)이 바운딩박스로서 의미가 있는지 없는지(즉 영역에 물체가 있는지)를 판단하는 것이다.</li>
<li>anchor boxes가 필요한데, 이것은 미리 정해놓은 바운딩박스의 크기이다. 내가 이 영역에 어떤 크기의 물체가 있을 것 같다라는 예상을 전제로 만들어 놓은 것임.</li>
<li>Fully Conv 레이어가 사용됨.</li>
</ul>
</li>
<li>YOLO<ul>
<li>extremely fast object detection algorithm</li>
<li>It simultaneously predicts multiple bounding boxes and class probabilities.<ul>
<li>No explicit bounding box sampling (compared with Faster R-CNN)</li>
</ul>
</li>
<li><img src="/image/image-20210812103801983.png" alt><ul>
<li>이미지 안에 찾고싶은 물체의 중앙이 그리드 안에 들어가면, 그 그리드 셋이 해당 물체의 바운딩 박스와 해당 물체가 무엇인지 같이 예측을 해야 한다.</li>
<li>이 때 B개의 바운딩 박스를 예측하게 된다. 이후 바운딩박스의 refinement(x/y/w/h)를 예측하고, 각각의 그리드셋이 속하는 중점의 오브젝트가 어떤 클래스인지 예측한다.</li>
<li>이 두 가지 정보를 취합하게 되면 박스와 박스가 어떤 클래스인지 예측할 수 있다.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div><a class="article-more button is-small is-size-7" href="/Computer-Vision-Applications-Semantic-Segmentation-and-Detection/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-11T09:20:36.000Z" title="2021. 8. 11. 오후 6:20:36">2021-08-11</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:21:14.000Z" title="2021. 8. 22. 오후 6:21:14">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">10분안에 읽기 (약 1488 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Convolution-intro/">Convolution 소개</a></h1><div class="content"><p>파라미터 수 손으로 직접 계산해보기</p>
<p><img src="/image/image-20210811102654457.png" alt></p>
<p>알렉스넷의 파라미터 수 구하기</p>
<p><img src="/image/image-20210811103940850.png" alt></p>
<p>input = 224 <em> 224 </em> 3<br>filter = 11 <em> 11 </em> 3<br>fisrt param = $11<em>11</em>3<em>48</em>2 ~= 35k$</p>
<h1 id="Modern-CNN"><a href="#Modern-CNN" class="headerlink" title="Modern CNN"></a>Modern CNN</h1><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>네트워크가 두 개로 나뉘어져 있다. 당시 GPU가 부족했기 때문임. 두 장의 GPU로 학습하고 합쳤다. 인풋에 $11 * 11$ 필터를 사용했는데, 파라미터 관점에서 좋진 않다. 상대적으로 많은 파라미터가 필요하기 때문. 이후 5개의 Convolution 레이어와 3개의 Dense 레이어를 사용한다. 최근 200-300개 네트워크를 가진 신경망에 비하면 Light한 편이다.</p>
<h4 id="Key-Ideas"><a href="#Key-Ideas" class="headerlink" title="Key Ideas"></a>Key Ideas</h4><ul>
<li>Rectified Linear Unit(ReLU) 활성화 함수를 사용했다. $ReLU = max(0, x)$<ul>
<li>리니어 모델이 갖는 좋은 성질들을 가질 수 있게 한다.</li>
<li>리니어 모델들의 성질을 가지고 있기 때문에 학습하는 SGD나 Gradient Descent로 학습을 용이하게 한다.</li>
<li>활성화함수를 사용할 때 이전에 많이 활용하던 Sigmoid나 tanh 같은 경우 값이 커지면 슬로프가 줄어들게 된다. 슬로프가 결국 기울기니까, 뉴런의 값이 많이 크면(0에서 벗어나면) Gradient Slope는 0에 가까워진다. 이 때 Vanishing Gradient 문제가 발생할 수 있는데, ReLU를 사용하면 해당 문제를 해소할 수 있음</li>
</ul>
</li>
<li>GPU Implementation (2 GPUs)</li>
<li>Local Response Normalization(어떠한 입력 공간에서 Response가 많이 나오는 부분을 죽이는 것임. 최근엔 많이 사용되지 않음), Overlapping pooling</li>
<li>Data Augmentation</li>
<li>Dropout</li>
</ul></div><a class="article-more button is-small is-size-7" href="/Convolution-intro/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-10T09:19:10.000Z" title="2021. 8. 10. 오후 6:19:10">2021-08-10</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:19:53.000Z" title="2021. 8. 22. 오후 6:19:53">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">25분안에 읽기 (약 3725 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Optimization-intro/">Optimization 소개</a></h1><div class="content"><p>“Language is the source of misunderstandings” - Antoine de Saint-Exupery (1900-1944)</p>
<p>용어에 대한 정리를 하고 넘어가야 이후에 오해가 생기지 않는다. 용어 통일이 가장 중요하기 때문에 용어에 대한 명확한 컨셉을 잡아볼 것임.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h3><ul>
<li>First-order iterative optimization algorithm for finding a local minimum of a differentiable function.</li>
<li>찾고자 하는 파라미터에 대해서 손실함수를 미분한 편미분값을 가지고 학습을 하겠다는 것임.</li>
<li>Local minimum: 손실함수를 미분했을 때 극소적으로 좋은 로컬 미니멈을 찾는 것을 목적으로 함.</li>
</ul>
<h2 id="Important-Concepts-in-Optimization"><a href="#Important-Concepts-in-Optimization" class="headerlink" title="Important Concepts in Optimization"></a>Important Concepts in Optimization</h2><ul>
<li><p>Generalization (일반화)</p>
<ul>
<li>대부분의 경우 일반화 성능을 높이는 것이 목적이다.</li>
<li>일반화 성능을 높이기만 하면 좋은 것인가?<ul>
<li>일반적으로 학습을 시키게 되면 Iteration이 지나면서 Training Error를 줄이게 되는데, Training Error가 0이 되었다고 해서 우리가 항상 원하는 최적값에 도달했다는 보장이 없다.</li>
<li>일반적으로 Training error가 주어지지만, 어느정도 시간이 지나고 나면 Test Error가 커짐, 즉 학습에 사용하지 않은 데이터에 대해서는 성능이 오히려 떨어지게 된다.</li>
<li>즉, 일반적으로 일반화는 테스트에러와 트레이닝 에러의 갭을 줄이는 것을 의미한다.</li>
<li>만약 우리 네트워크가 안좋아서 학습데이터에 대한 성능이 안좋으면, 일반화의 퍼포먼스가 좋다고 해서 테스트 데이터의 성능이 좋다고 말할 수 없다.</li>
<li>일반화의 성능은 테스트와 트레이닝 에러의 갭을 말하기 때문이다.</li>
</ul>
</li>
</ul>
</li>
<li><p>Under-fitting vs. over-fitting</p>
<ul>
<li><p>학습데이터에 대해서는 잘 동작을 하지만 테스트데이터에 대해서 잘 동작하지 않는 것을 OverFitting이라고 한다.</p>
<p><img src="/image/image-20210810115422718.png" alt></p>
</li>
</ul>
</li>
<li><p>Cross validation</p>
<ul>
<li>일반적으로 데이터가 분리되어 있음 (Train, Test, Validate)</li>
<li>보통은 학습 데이터로 학습시킨 모델이 학습에 사용되지 않은 밸리데이션 데이터를 기준으로 학습이 잘 되었는지 확인하는 과정이다.</li>
<li>하지만, 트레인과 테스트를 반반으로 했을 때, 트레인을 80 테스트를 20으로 했을 때 등 Split 범위에 따라서 학습의 퍼포먼스가 달라질 수 있다. 이러한 것을 해결하고자 하는 것이 Cross Validation이다. (혹은 K-Fold Validation)</li>
<li>네트워크를 학습할 때 수많은 파라미터가 존재한다. 또한 Hyper Parameter들에 대한 기준이 없다. 따라서 Cross-validation을 통해 최적의 Parameter Sets 을 찾고, 파라미터를 보정한 상태에서 모든 학습데이터를 학습에 사용해야 더 많은 데이터를 사용할 수 있다.</li>
<li>Test Data는 어떠한 방법으로든 학습에 사용되어서는 안된다. 즉, 학습에는 Train과 Validate 데이터만을 이용해야 한다.</li>
</ul>
</li>
<li><p>Bias-variance tradeoff</p>
<ul>
<li><p><img src="/image/image-20210810115942627.png" alt></p>
</li>
<li><p>사격을 할 때 항상 같은 곳에만 찍히면 (원점이 아니더라도) 좋은 것이다. 전체 모델을 어느정도 평준화 시키면 최적값에 도달할 가능성이 많기 때문이다. 이것을 Low Variance라고 한다. (출력이 얼마나 일관적으로 나오는 지)</p>
</li>
<li><p>이것에 반해 Variance가 크면 비슷한 입력이 들어와도 출력이 많이 달라지는 것을 의미한다.</p>
</li>
<li><p>Bias라는 것은 출력에 따른 평균적으로 True Target에 접근하는 정도를 의미하며, Bias가 크면 Mean에서 많이 벗어나는 것을 의미한다.</p>
</li>
<li><p>학습 데이터에 Noise가 껴있다고 가정했을 때 내가 이 노이즈가 껴있는 타겟 데이터를 미니마이즈하는 것에 대하여 세 파트로 나뉘어진다. 내가 미니마이즈하는 것은 하나의 값(cost)이지만, 그 값은 세 파트로 나뉘어져 있어서 한 파트를 줄이면 다른 파트가 커질 수밖에 없는 Trade-off 관계이다.</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{E}\left[(t-\hat{f})^{2}\right] &=\mathbb{E}\left[(t-f+f-\hat{f})^{2}\right] \\
&=\ldots \\
&=\mathbb{E}\left[\left(f-\mathbb{E}[\hat{f}]^{2}\right)^{2}\right]+\mathbb{E}\left[(\mathbb{E}[\hat{f}]-\hat{f})^{2}\right]+\mathbb{E}[\epsilon]
\end{aligned}</script><p>위 식에서 cost를 minimize한다는 것은 bias와 variance, noise를 minimize 한다는 것을 의미한다.</p>
</li>
</ul>
</li>
<li><p>Bootstrapping</p>
<ul>
<li>신발끈을 말하는 것이며, 그 뜻은 신발끈을 들어올려 하늘을 날겠다라는 허황된 뜻임.</li>
<li>딥러닝에서는 학습 데이터가 100개가 있다고 하면, 100개 중 80개를 사용하겠다 등 일부만 뽑아서 사용한다는 것을 의미한다.</li>
<li>이렇게 했을 때 하나의 입력에 대해서 각 모델들의 출력이 달라질 수 있다. 이 때 각 모델들의 예측값들이 얼마나 일치를 이루는지 보고 전체 모델들의 특성을 알고자 하는 것이다.</li>
<li>학습데이터가 고정되어 있을 때 subsampling을 통해 여러 학습데이터를 만들고 그것을 이용하여 여러 모델 혹은 metric을 만들겠다는 것임.</li>
</ul>
</li>
<li><p>Baggin and boosting</p>
<ul>
<li>Bagging(Bootstrapping aggregating)</li>
<li>학습데이터를 여러 개를 만들어서 (Booststrapping) 여러 모델을 만들고 그 모델의 output들을 가지고 평균을 내겠다는 뜻임.</li>
<li>학습데이터가 고정되어 있으면 이것을 모두 이용하여 하나의 결과를 내는 것이 좋을 것 같지만 사실은 그렇지 않다. N개의 모델을 만들고, N개의 모델의 출력값의 평균이나 Voting을 통해 나오는 결과를 사용하는 것이 보통 성능이 더 좋다.</li>
<li>Boosting: 학습데이터를 시퀀셜하게 바라봐서 간단한 모델을 만들고, 모델에 학습데이터를 다 넣어본다. 모델에서 80개는 잘 예측을 했지만 20개는 잘 안되었다. 이 때 모델을 하나를 더 만드는데 전에 안되었던 20개에 데이터를 잘 예측하는 모델을 만든다. 이렇게 모델들을 만들고 합친 이후에 하나의 struct learner를 만들고, 그 weight를 찾는 방식을 말한다.</li>
</ul>
</li>
</ul>
<h2 id="Practical-Gradient-Descent-Methods"><a href="#Practical-Gradient-Descent-Methods" class="headerlink" title="Practical Gradient Descent Methods"></a>Practical Gradient Descent Methods</h2><h3 id="Stochastic-gradient-Descent"><a href="#Stochastic-gradient-Descent" class="headerlink" title="Stochastic gradient Descent"></a>Stochastic gradient Descent</h3><ul>
<li>하나의 샘플을 이용</li>
</ul></div><a class="article-more button is-small is-size-7" href="/Optimization-intro/#more">자세히 보기</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time datetime="2021-08-09T09:17:29.000Z" title="2021. 8. 9. 오후 6:17:29">2021-08-09</time>&nbsp;게시 됨</span><span class="level-item"><time datetime="2021-08-22T09:17:54.000Z" title="2021. 8. 22. 오후 6:17:54">2021-08-22</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/AI/">AI</a></span><span class="level-item">몇 초안에 읽기 (약 100 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Multi-Layer-Perceptron/">뉴럴 네트워크 - Multi Layer Perceptron</a></h1><div class="content"><blockquote>
<p>Neural networks are computing systems vaguely inspired by the biological neural networks that constitute animal brains.</p>
</blockquote>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \operatorname{loss}}{\partial w} &=\frac{\partial}{\partial w} \frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\hat{y}_{i}\right)^{2} \\
&=\frac{\partial}{\partial w} \frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-w x_{i}-b\right)^{2} \\
&=-\frac{1}{N} \sum_{i=1}^{N}-2\left(y_{i}-w x_{i}-b\right) x_{i}
\end{aligned}</script><script type="math/tex; mode=display">
\begin{aligned}
&w \leftarrow w-\eta \frac{\partial \operatorname{loss}}{\partial w} \\
&b \leftarrow b-\eta \frac{\partial l o s s}{\partial b}
\end{aligned}</script></div><a class="article-more button is-small is-size-7" href="/Multi-Layer-Perceptron/#more">자세히 보기</a></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/image/avatar.jpg" alt="YOHAI"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">YOHAI</p><p class="is-size-6 is-block">Your Own Humanistic AI</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">66</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">22</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">26</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/l-yohai" target="_blank" rel="external nofollow noopener noreferrer">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="external nofollow noopener noreferrer" title="Email" href="mailto:yohan9612@yonsei.ac.kr"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="external nofollow noopener noreferrer" title="Github" href="https://github.com/l-yohai"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="external nofollow noopener noreferrer" title="Linkedin" href="https://www.linkedin.com/in/l-yohai/"><i class="fab fa-linkedin"></i></a></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/42-Life/"><span class="level-start"><span class="level-item">42 Life</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Boostcamp-AI-Tech/"><span class="level-start"><span class="level-item">Boostcamp AI Tech</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Boostcamp-AI-Tech/Master-Class/"><span class="level-start"><span class="level-item">Master Class</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Competition/"><span class="level-start"><span class="level-item">Competition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Diary/"><span class="level-start"><span class="level-item">Diary</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/categories/Paper-Review/"><span class="level-start"><span class="level-item">Paper Review</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Problem-Solving/"><span class="level-start"><span class="level-item">Problem Solving</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/Project/"><span class="level-start"><span class="level-item">Project</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/Tips/"><span class="level-start"><span class="level-item">Tips</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Study/"><span class="level-start"><span class="level-item">Study</span></span><span class="level-end"><span class="level-item tag">30</span></span></a><ul><li><a class="level is-mobile" href="/categories/Study/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/C/"><span class="level-start"><span class="level-item">C</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Math-for-AI/"><span class="level-start"><span class="level-item">Math for AI</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Study/NLP/MRC/"><span class="level-start"><span class="level-item">MRC</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Study/Network/"><span class="level-start"><span class="level-item">Network</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Visualization/"><span class="level-start"><span class="level-item">Visualization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Yonsei/"><span class="level-start"><span class="level-item">Yonsei</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/fur-Musik/"><span class="level-start"><span class="level-item">für Musik</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/42-Seoul/"><span class="tag">42 Seoul</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42Seoul/"><span class="tag">42Seoul</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42%EC%84%9C%EC%9A%B8/"><span class="tag">42서울</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42%EC%84%9C%EC%9A%B8-%EB%B3%B8%EA%B3%BC%EC%A0%95/"><span class="tag">42서울 본과정</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/42%EC%84%9C%EC%9A%B8-%ED%9B%84%EA%B8%B0/"><span class="tag">42서울 후기</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AI-%EB%8C%80%ED%9A%8C-%ED%98%91%EC%97%85-%ED%94%8C%EB%9E%98%EB%8B%9D%EA%B0%80%EC%9D%B4%EB%93%9C/"><span class="tag">AI, 대회, 협업, 플래닝가이드</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Franz-Liszt/"><span class="tag">Franz Liszt</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kakao-I-Open-Builder/"><span class="tag">Kakao I Open Builder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/La-Piscine/"><span class="tag">La Piscine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Papago-NMT-API/"><span class="tag">Papago NMT API</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Teachable-Machine/"><span class="tag">Teachable Machine</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tech-Seminar/"><span class="tag">Tech Seminar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VoyagerX/"><span class="tag">VoyagerX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WaveNet/"><span class="tag">WaveNet</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word2Vec/"><span class="tag">Word2Vec</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B3%B5%ED%86%B5%EA%B3%BC%EC%A0%95/"><span class="tag">공통과정</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%82%A8%EC%84%B8%EB%8F%99/"><span class="tag">남세동</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="tag">딥러닝</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B3%B4%EC%9D%B4%EC%A0%80%EC%97%91%EC%8A%A4/"><span class="tag">보이저엑스</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"><span class="tag">시각화</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%B4%EC%A0%95/"><span class="tag">열정</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9D%B4%EB%84%88%EC%84%9C%ED%81%B4/"><span class="tag">이너서클</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9D%B4%EB%85%B8%EB%B2%A0%EC%9D%B4%EC%85%98%EC%95%84%EC%B9%B4%EB%8D%B0%EB%AF%B8/"><span class="tag">이노베이션아카데미</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%B1%97%EB%B4%87/"><span class="tag">챗봇</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%B4%88%EC%A0%88%EA%B8%B0%EA%B5%90-%EC%97%B0%EC%8A%B5%EA%B3%A1/"><span class="tag">초절기교 연습곡</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%86%A1/"><span class="tag">카카오톡</span><span class="tag">2</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><figure class="media-left"><a class="image" href="/AI-Bookathon/"><img src="/image/3rd_ai_bookathon.jpg" alt="AI Bookathon 대상 후기"></a></figure><div class="media-content"><p class="date"><time datetime="2021-11-17T21:54:58.000Z">2021-11-18</time></p><p class="title"><a href="/AI-Bookathon/">AI Bookathon 대상 후기</a></p><p class="categories"><a href="/categories/Competition/">Competition</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-16T05:29:55.000Z">2021-10-16</time></p><p class="title"><a href="/PStage-MRC-7-Linking-MRC-and-Retrieval/">PStage MRC 7강 - Linking MRC and Retrieval</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-14T21:24:41.000Z">2021-10-15</time></p><p class="title"><a href="/PStage-MRC-6-Scaling-up-with-FAISS/">PStage MRC 6강 - Scaling up with FAISS</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-13T19:59:34.000Z">2021-10-14</time></p><p class="title"><a href="/PStage-MRC-4-5-Passage-Retrieval-Sparse-Embedding-Dense-Embedding/">PStage MRC 4-5강 - Passage Retrieval - Sparse Embedding, Dense Embedding</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-10-13T02:50:23.000Z">2021-10-13</time></p><p class="title"><a href="/PStage-MRC-3-Generation-based-MRC/">PStage MRC 3강 - Generation-based MRC</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/NLP/">NLP</a> / <a href="/categories/Study/NLP/MRC/">MRC</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/11/"><span class="level-start"><span class="level-item">11월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/10/"><span class="level-start"><span class="level-item">10월 2021</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">9월 2021</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/08/"><span class="level-start"><span class="level-item">8월 2021</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">4월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">12월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">9월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/08/"><span class="level-start"><span class="level-item">8월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/06/"><span class="level-start"><span class="level-item">6월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/05/"><span class="level-start"><span class="level-item">5월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/04/"><span class="level-start"><span class="level-item">4월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">3월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">2월 2020</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/image/logo.png" alt="YOHAI" height="28"></a><p class="is-size-7"><span>&copy; 2023 Yohan Lee</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/l-yohai"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>